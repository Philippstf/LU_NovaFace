# ğŸ¯ nuva face - AI Lip Enhancement Prediction

MVP eines Machine Learning Systems zur Vorhersage von Lippenunterspritzungs-Ergebnissen.

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Activate virtual environment
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Airtable Configuration
```bash
# Copy environment template
cp .env.example .env

# Edit .env with your Airtable credentials:
# AIRTABLE_API_KEY=your_api_key
# AIRTABLE_BASE_ID=your_base_id  
# AIRTABLE_TABLE_NAME=your_table_name
```

### 3. Extract Data from Airtable
```bash
python scripts/extract_data.py
```

### 4. Start Training
```bash
python scripts/train_model.py --epochs 100 --batch-size 8
```

## ğŸ“ Project Structure

```
LU_NovaFace/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/              # Data loading & preprocessing
â”‚   â”‚   â”œâ”€â”€ airtable_extractor.py  # Airtable API integration
â”‚   â”‚   â””â”€â”€ dataset.py             # PyTorch dataset & transforms
â”‚   â”œâ”€â”€ models/            # Neural network architectures  
â”‚   â”‚   â”œâ”€â”€ generator.py           # Generator models
â”‚   â”‚   â”œâ”€â”€ discriminator.py       # Discriminator models
â”‚   â”‚   â””â”€â”€ gan.py                 # Complete GAN system
â”‚   â””â”€â”€ training/          # Training pipeline
â”‚       â””â”€â”€ trainer.py             # Training loop & logging
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Downloaded images & metadata
â”‚   â”œâ”€â”€ processed/         # Preprocessed data  
â”‚   â””â”€â”€ splits/            # Train/val/test splits
â”œâ”€â”€ scripts/               # Utility scripts
â”œâ”€â”€ configs/               # Configuration files
â””â”€â”€ checkpoints/           # Model checkpoints
```

## ğŸ® Training Options

```bash
# Basic training
python scripts/train_model.py

# Advanced options
python scripts/train_model.py \
    --epochs 200 \
    --batch-size 16 \
    --lr-g 1e-4 \
    --lr-d 2e-4 \
    --generator unet \
    --discriminator multiscale \
    --image-size 512
```

## ğŸ“Š Model Architectures

### Generators
- **ConditionalGenerator**: ResNet-based with condition injection
- **UNetGenerator**: U-Net with skip connections (better detail preservation)

### Discriminators  
- **PatchDiscriminator**: PatchGAN for efficient patch-based classification
- **MultiScaleDiscriminator**: Multi-resolution discrimination

### Loss Functions
- **Adversarial Loss**: GAN objective
- **L1 Loss**: Pixel-wise reconstruction (Î»=100)
- **Perceptual Loss**: VGG-based feature matching (Î»=10) 
- **Style Loss**: Gram matrix matching (Î»=50)

## ğŸ”§ Data Pipeline

1. **Airtable Extraction**: Downloads images and metadata
2. **Preprocessing**: Resize, normalize, augment images
3. **Condition Encoding**: Convert treatment parameters to embeddings
4. **Data Splits**: 80% train, 10% validation, 10% test

## ğŸ“ˆ Monitoring

- **Wandb Integration**: Automatic logging of losses, samples, metrics
- **Checkpoints**: Best model and periodic saves
- **Sample Generation**: Visual progress tracking every 5 epochs

## ğŸ¯ Expected Input/Output

### Input
- **Before Image**: 512x512 RGB image of lip region
- **Treatment Parameters**:
  - Product type (e.g., "hyaluronic_acid")
  - Volume (ml, e.g., 0.7)
  - Region (e.g., "upper_lip")
  - Gender, Age

### Output
- **After Image**: 512x512 RGB predicted result

## ğŸ“ Airtable Schema

Your Airtable should have these columns:
- `Vorher-Foto`: Attachment field (before image)
- `Nachher-Foto`: Attachment field (after image)
- `Produkt`: Single select (product type)
- `Volumen pro Region`: Number (ml volume)
- `Region`: Single select (treatment region)
- `Geschlecht`: Single select (gender)
- `Alter`: Number (age)
- `Notizen`: Long text (notes)

## ğŸš¨ Troubleshooting

### Common Issues

**"No CUDA device found"**
- Install PyTorch with CUDA support
- Check GPU availability with `nvidia-smi`

**"Airtable API Error"**
- Verify API key and base ID in `.env`
- Check table permissions

**"Out of memory"**
- Reduce batch size: `--batch-size 4`
- Reduce image size: `--image-size 256`

### System Requirements
- **GPU**: 8GB+ VRAM recommended
- **RAM**: 16GB+ system memory
- **Storage**: 50GB+ for data and checkpoints

## ğŸ“š Next Steps

1. **Data Collection**: Increase dataset to 500+ samples
2. **Model Improvements**: Experiment with diffusion models
3. **Evaluation**: Clinical validation with medical experts
4. **Deployment**: REST API with FastAPI
5. **Frontend**: Web interface for easy testing

## ğŸ“„ License

MIT License - See LICENSE file for details.

---

**Generated with Claude Code** ğŸ¤–